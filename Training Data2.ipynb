{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63229a74-00f9-4544-9cb5-c04bc9bc3240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in train directory: 54706\n",
      "Total images in valid directory: 463\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "# Đường dẫn đến thư mục chứa ảnh\n",
    "img_dir = 'C:/Users/ADMIN/Desktop/data/'\n",
    "\n",
    "# Đọc thông tin từ các file metadata\n",
    "df_train_meta = pd.read_csv('C:/Users/ADMIN/Desktop/data/train_meta.csv')\n",
    "df_valid_meta = pd.read_csv('C:/Users/ADMIN/Desktop/data/valid_meta.csv')\n",
    "\n",
    "# Tạo cột 'image_filename' nếu nó chưa tồn tại\n",
    "df_train_meta['image_filename'] = df_train_meta['patient_id'].astype(str) + '_' + df_train_meta['image_id'].astype(str) + '.png'\n",
    "df_valid_meta['image_filename'] = df_valid_meta['patient_id'].astype(str) + '_' + df_valid_meta['image_id'].astype(str) + '.png'\n",
    "\n",
    "# Đường dẫn đến thư mục đích cho ảnh train và valid\n",
    "train_dir = 'C:/Users/ADMIN/Desktop/data/train_images'\n",
    "valid_dir = 'C:/Users/ADMIN/Desktop/data/valid_images'\n",
    "\n",
    "# Tạo thư mục train và valid nếu chúng chưa tồn tại\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "# Di chuyển hình ảnh vào thư mục đích\n",
    "for filename in df_train_meta['image_filename']:\n",
    "    src_file_path = os.path.join(img_dir, filename)\n",
    "    dst_file_path = os.path.join(train_dir, filename)\n",
    "    if os.path.isfile(src_file_path):  # Kiểm tra xem file có tồn tại\n",
    "        copyfile(src_file_path, dst_file_path)\n",
    "\n",
    "for filename in df_valid_meta['image_filename']:\n",
    "    src_file_path = os.path.join(img_dir, filename)\n",
    "    dst_file_path = os.path.join(valid_dir, filename)\n",
    "    if os.path.isfile(src_file_path):  # Kiểm tra xem file có tồn tại\n",
    "        copyfile(src_file_path, dst_file_path)\n",
    "\n",
    "print(f'Total images in train directory: {len(os.listdir(train_dir))}')\n",
    "print(f'Total images in valid directory: {len(os.listdir(valid_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee682497-7bba-44c4-b5f8-a5d85157c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data set\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, meta_df, img_dir, transform=None):\n",
    "        \n",
    "        self.df = meta_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get label from meta data\n",
    "        label = self.df.iloc[idx]['cancer']\n",
    "        img_filename = self.df.iloc[idx]['image_filename']  # make sure this column exists in your dataframe\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, img_filename)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Get metadata features\n",
    "        feature_names = [\n",
    "            'age', \n",
    "            'laterality_L', 'laterality_R', \n",
    "            'view_AT', 'view_CC', 'view_MLO',\n",
    "            'implant_0', 'implant_1'\n",
    "                        ]\n",
    "        \n",
    "        meta_features = self.df[feature_names]\n",
    "        meta_features = meta_features.iloc[idx, :].to_numpy()\n",
    "\n",
    "        \n",
    "        return img, meta_features, label\n",
    "\n",
    "# Defining the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Initialize the datasets\n",
    "train_dataset = MammographyDataset(\n",
    "    meta_df=df_train_meta,\n",
    "    img_dir='C:/Users/ADMIN/Desktop/data/train_images',\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "valid_dataset = MammographyDataset(\n",
    "    meta_df=df_valid_meta,\n",
    "    img_dir='C:/Users/ADMIN/Desktop/data/valid_images',\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Initialize the DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f62c0fa-1694-4253-8756-ef47359a294a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MammographyModel(\n",
       "  (rnet): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=508, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MammographyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnet = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.rnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.rnet.fc = nn.Linear(in_features=2048, out_features=500)\n",
    "        self.fc1 = nn.Linear(508, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, img, meta_features):\n",
    "        resnet_out = self.rnet(img)\n",
    "        resnet_out = torch.sigmoid(resnet_out)\n",
    "\n",
    "        if meta_features.dim() == 1:\n",
    "            meta_features = meta_features.unsqueeze(0)  \n",
    "\n",
    "        x_final = torch.cat((resnet_out, meta_features), dim=1)\n",
    "\n",
    "        x_final = self.fc1(x_final)\n",
    "        out = self.sigmoid(x_final)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "model = MammographyModel()\n",
    "model_path = 'C:/Users/ADMIN/Desktop/saved_models/model_epoch_25.pth'  \n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcc41f2-84c7-4437-a949-6f7a39a97432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation set: 0.69\n",
      "Accuracy on validation set: 58.10%\n",
      "Sensitivity on validation set: 0.33\n",
      "Specificity on validation set: 0.84\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Khai báo hàm mất mát\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "# Lưu dự đoán và nhãn thực tế\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "# Đánh giá mô hình\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, meta_features, labels in valid_loader:\n",
    "        # Đảm bảo rằng đầu vào cho mô hình có cùng kiểu dữ liệu\n",
    "        images = images.float()\n",
    "        meta_features = meta_features.float()\n",
    "        labels = labels.float()\n",
    "\n",
    "        outputs = model(images, meta_features)\n",
    "        loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        predicted = outputs.round()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "\n",
    "        all_labels.extend(labels.tolist())\n",
    "        all_preds.extend(predicted.squeeze().tolist())\n",
    "\n",
    "\n",
    "average_loss = total_loss / len(valid_loader)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Loss on validation set: {average_loss:.2f}')\n",
    "print(f'Accuracy on validation set: {accuracy:.2f}%')\n",
    "print(f'Sensitivity on validation set: {sensitivity:.2f}')\n",
    "print(f'Specificity on validation set: {specificity:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6223492-9173-4a59-8c97-abb5c913f1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xác suất ung thư: 0.73\n",
      "Dự đoán: Có dấu hiệu của bệnh ung thư vú.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def prepare_metadata(age, laterality, view, implant, df_train_meta):\n",
    "    \n",
    "    age_normalized = (age - df_train_meta['age'].min()) / (df_train_meta['age'].max() - df_train_meta['age'].min())\n",
    "\n",
    "    laterality_features = [1.0 if laterality == 'L' else 0.0, 1.0 if laterality == 'R' else 0.0]\n",
    "    \n",
    "    view_features = [1.0 if view == 'AT' else 0.0, 1.0 if view == 'CC' else 0.0, 1.0 if view == 'MLO' else 0.0]\n",
    "    \n",
    "    implant_features = [1.0 if implant == 0 else 0.0, 1.0 if implant == 1 else 0.0]\n",
    "    \n",
    "    meta_features = np.array([age_normalized] + laterality_features + view_features + implant_features, dtype=np.float32)\n",
    "    \n",
    "    return torch.tensor(meta_features).unsqueeze(0)  \n",
    "\n",
    "\n",
    "def predict_cancer(image_path, age, laterality, view, implant, model, df_train_meta):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=1),  \n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "  \n",
    "    img = Image.open(image_path).convert('L')  \n",
    "    img = transform(img).unsqueeze(0)  \n",
    "\n",
    " \n",
    "    meta_features = prepare_metadata(age, laterality, view, implant, df_train_meta)\n",
    "\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        preds = model(img, meta_features)\n",
    "        cancer_prob = torch.sigmoid(preds).item() \n",
    "\n",
    "    print(\"Xác suất ung thư: {:.2f}\".format(cancer_prob))\n",
    "    if cancer_prob > 0.5:\n",
    "        print(\"Dự đoán: Có dấu hiệu của bệnh ung thư vú.\")\n",
    "    else:\n",
    "        print(\"Dự đoán: Không có dấu hiệu của bệnh ung thư vú.\")\n",
    "\n",
    "image_path = 'C:/Users/ADMIN/Desktop/data/valid_images/52181_1884342055.png'\n",
    "age = 45  \n",
    "laterality = 'L'  \n",
    "view = 'MLO'  \n",
    "implant = 0  \n",
    "\n",
    "predict_cancer(image_path, age, laterality, view, implant, model, df_train_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8e526-295c-4ead-89fc-5af678958d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e4aba-ab1a-4114-a3fd-3f900d7dab55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
